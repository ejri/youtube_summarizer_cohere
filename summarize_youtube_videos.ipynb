{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83TkFCvBK-1Z",
        "outputId": "296c6457-4463-44e2-8e4e-82dea7e15a8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install the following libraries: cohere to use the x-large model. \n",
        "!pip install cohere youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhJ8Xg6ELQCk",
        "outputId": "16cd81ca-3b12-49ae-c2e4-c367e99c73d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cohere\n",
            "  Downloading cohere-3.3.3.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.5.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from cohere) (2.25.1)\n",
            "Collecting urllib3~=1.26\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (2022.12.7)\n",
            "Building wheels for collected packages: cohere\n",
            "  Building wheel for cohere (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cohere: filename=cohere-3.3.3-cp38-cp38-linux_x86_64.whl size=15682 sha256=672aed398b0d83d168b4a55dd8eb09e4f4d591aeebecb3c2d6513aed5dcfc431\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/e7/ac/033673c03849f03bf424822e247487cd9b89dcb4e5ef609901\n",
            "Successfully built cohere\n",
            "Installing collected packages: urllib3, youtube_transcript_api, cohere\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed cohere-3.3.3 urllib3-1.26.14 youtube_transcript_api-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GLi6usePVwQH"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/weblm/WebLM_interactive_src/cohereapikey.txt  /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6vGGA41hSge",
        "outputId": "60f6ad43-34e8-4ada-fe16-a86ab786b0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!mkdir /content/response_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# summarize a youtube video using cohere's "
      ],
      "metadata": {
        "id": "gomDjMZ1nB4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import sys\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from time import time,sleep\n",
        "import re\n",
        "\n",
        "diagnostics = 0\n",
        "include_mentions = 0\n",
        "\n",
        "\n",
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "def save_file(filepath, content):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "co= cohere.Client(open_file('/content/cohereapikey.txt'))\n",
        "\n",
        "def get_video_id_from_video_id_or_url(video_id_or_url):\n",
        "    # fetch the video ID from the URL. if it's more that 11 characters long, crop it to make it 11. \n",
        "    if len(video_id_or_url) > 11:\n",
        "        return video_id_or_url[-11:]\n",
        "    else:\n",
        "        return video_id_or_url\n",
        "\n",
        "def get_chunks_from_youtube(video_id):\n",
        "    # fetch video's transcript\n",
        "    # and chunk it into several 5min intervals\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "    chunks = []\n",
        "\n",
        "    start_timestamp = 0.0\n",
        "    current_timestamp_mins = 0.0\n",
        "\n",
        "    current_chunk = []\n",
        "\n",
        "    for entry in transcript:\n",
        "        current_timestamp_mins = entry['start'] / 60.0\n",
        "\n",
        "        # chunk at 5 minutes intervals\n",
        "        if current_timestamp_mins - start_timestamp > 5:\n",
        "            # add current chunk to a list of chunks\n",
        "            chunks.append(current_chunk)\n",
        "            # then reset the start timestamp\n",
        "            start_timestamp = current_timestamp_mins\n",
        "            # reset current chunk\n",
        "            current_chunk = []\n",
        "\n",
        "        # append the chunk's text\n",
        "        current_chunk.append(entry['text'])\n",
        "\n",
        "    # the last chunk of the video\n",
        "    if len(current_chunk) > 0:\n",
        "        chunks.append(current_chunk)\n",
        "\n",
        "    print(f\"Found {len(chunks)} chunks\")\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(index, chunk):\n",
        "    chunk_str = \"\\n\".join(chunk)\n",
        "    prompt = f\"\"\"The following is a section of the transcript of a youtube video. It is section #{index+1}:\n",
        "    {chunk_str}\n",
        "    Briefly summarize this section of the transcript in 100 characters or less.\"\"\"\n",
        "\n",
        "    if diagnostics:\n",
        "        for line in prompt.split('\\n'):\n",
        "            print(f\"# {line}\")\n",
        "\n",
        "    \n",
        "    response = co.generate(\n",
        "                model='xlarge'\n",
        "                #model='command-beta',\n",
        "                prompt= prompt,\n",
        "                max_tokens=500,\n",
        "                temperature=1.8,\n",
        "                k=0,\n",
        "                p=0.65,\n",
        "                frequency_penalty=0.15,\n",
        "                presence_penalty=0.15,\n",
        "                stop_sequences=[],\n",
        "                return_likelihoods='NONE')\n",
        "    text_response = response.generations[0].text.strip()\n",
        "    text_response = re.sub('\\s+', ' ', text_response)\n",
        "    filename = '%s_logs.txt' % time()\n",
        "    with open('response_logs/%s' % filename, 'w') as outfile:\n",
        "        outfile.write('PROMPT:\\n\\n' + prompt + '\\n\\n==========\\n\\nRESPONSE:\\n\\n' + text_response)\n",
        "    with open('response.txt', 'w') as f:\n",
        "        f.write(text_response)\n",
        "    \n",
        "    if diagnostics:\n",
        "        print(f\"# Response: {text_response}\")\n",
        "    \n",
        "    return text_response\n",
        "\n",
        "def summarize_the_summaries(summaries):\n",
        "    max_retry = 5\n",
        "    retry = 0\n",
        "    summaries_str = \"\"\n",
        "    for index, summary in enumerate(summaries):\n",
        "        summaries_str += f\"Summary of chunk {index+1}:\\n{summary}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"The following are summaries of a youtube video in 5 minute chunks:\"\n",
        "    {summaries_str}\n",
        "    Summarize the summaries.\"\"\"\n",
        "\n",
        "    # prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
        "\n",
        "    if diagnostics:\n",
        "        for line in prompt.split('\\n'):\n",
        "            print(f\"# {line}\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            response = co.generate(\n",
        "                model='xlarge'\n",
        "                #model='command-beta',\n",
        "                prompt= prompt,\n",
        "                max_tokens=500,\n",
        "                temperature=1.8,\n",
        "                k=0,\n",
        "                p=0.65,\n",
        "                frequency_penalty=0.15,\n",
        "                presence_penalty=0.15,\n",
        "                stop_sequences=[],\n",
        "                return_likelihoods='NONE')\n",
        "            text_response = response.generations[0].text.strip()\n",
        "            text_response = re.sub('\\s+', ' ', text_response)\n",
        "            filename = '%s_log.txt' % time()\n",
        "            with open('response_logs/%s' % filename, 'w') as outfile:\n",
        "                outfile.write('PROMPT:\\n\\n' + prompt + '\\n\\n==========\\n\\nRESPONSE:\\n\\n' + text_response)\n",
        "            with open('response.txt', 'w') as f:\n",
        "                f.write(text_response)\n",
        "            return text_response\n",
        "        except Exception as oops:\n",
        "            retry += 1\n",
        "            if retry >= max_retry:\n",
        "                return \"error: %s\" % oops\n",
        "            print('Error communicating with Cohere:', oops)\n",
        "            sleep(1)\n",
        "\n",
        "    if diagnostics:\n",
        "        print(f\"# Response: {text_response}\")\n",
        "\n",
        "    return text_response\n",
        "\n",
        "def main():\n",
        "    # the video transcript\n",
        "    if len(sys.argv) < 2:\n",
        "        print(\"Usage: python3 sumvid.py <video id or url>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    video_id_or_url = sys.argv[1]\n",
        "\n",
        "    # if the video id or url is a url, extract the video id\n",
        "    video_id = get_video_id_from_video_id_or_url(video_id_or_url)\n",
        "\n",
        "    if len(sys.argv) > 2:\n",
        "        for arg in sys.argv[2:]:\n",
        "            if arg == \"--diagnostics\":\n",
        "                global diagnostics\n",
        "                diagnostics = True\n",
        "\n",
        "            if arg == \"--mentions\":\n",
        "                global include_mentions\n",
        "                include_mentions = True\n",
        "\n",
        "    chunks = get_chunks_from_youtube(video_id)\n",
        "\n",
        "    if len(chunks) == 0:\n",
        "        print(\"No chunks found\")\n",
        "    elif len(chunks) == 1:\n",
        "        summary = summarize_chunk(0, chunks[0])\n",
        "        print(f\"\\nSummary: {summary}\")\n",
        "\n",
        "    else:\n",
        "        # summarize each chunk\n",
        "        summaries = []\n",
        "        for index, chunk in enumerate(chunks):\n",
        "            summary = summarize_chunk(index, chunk)\n",
        "            summaries.append(summary)\n",
        "            print(f\"\\nSummary of chunk {index+1}: {summary}\")\n",
        "\n",
        "        # compile the summaries\n",
        "        summary_of_summaries = summarize_the_summaries(summaries)\n",
        "\n",
        "        print(f\"\\nSummary of summaries: {summary_of_summaries}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2glh9aornBqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with mentions of people and places\n",
        "%cd /content\n",
        "!python3 /content/summarize_youtube.py https://www.youtube.com/watch?v=3m2Cpbpr1zM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkm2l1pEpo3e",
        "outputId": "27d62a1b-5e99-4ad1-d9a4-9164e776975b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Found 1 chunks\n",
            "\n",
            "Summary: In this section of the transcript, David's team is discussing a mug that they think belongs to Lee. They are trying to determine if the mug is really Lee's mug or not.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/summarize_youtube.py https://www.youtube.com/watch?v=JsLH0SeqAEc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM3HyxoqtPSA",
        "outputId": "88131302-b1f6-46b3-c907-ad2a5c84c23c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 chunks\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/summarize_youtube.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/content/summarize_youtube.py\", line 176, in main\n",
            "    summary = summarize_chunk(0, chunks[0])\n",
            "  File \"/content/summarize_youtube.py\", line 86, in summarize_chunk\n",
            "    text_response = response.generations[0].text.strip()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/response.py\", line 54, in __getattribute__\n",
            "    return attr.resolve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/response.py\", line 41, in resolve\n",
            "    self._result = self._getter(self._request.result())\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/client.py\", line 408, in __request\n",
            "    raise CohereError(\n",
            "cohere.error.CohereError: blocked input: please adjust your prompt and try again, as it may be a potential violation of our Usage Guidelines (https://docs.cohere.ai/usage-guidelines/).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/summarize_youtube.py https://youtu.be/_psRCXRyWq8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBIpwdMNqa5H",
        "outputId": "4b74dae5-af96-42f5-ca57-df128b9c2589"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 chunks\n",
            "\n",
            "Summary: Section #1 of the transcript describes a patient's knee surgery to repair a torn meniscus. The meniscus helps spread weight evenly across the joint and provides stability. The surgery involves using an arthroscopic punch and shaver to remove the torn fragment, and a shaver to remove any debris or loose fragments. In young patients, a torn meniscus can occur due to a forceful action such as a deep squat or pivot, while in older patients less force is required. The patient normally goes home the same day and can return to driving and sports within four to six weeks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/summarize_youtube.py https://www.youtube.com/watch?v=cTxBLn-DoEQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu9zID94br_x",
        "outputId": "d944ca5d-6bf5-443c-afeb-0c99b1f29d2e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 chunks\n",
            "\n",
            "Summary of chunk 1: The section is a brief introduction of the speakers for the video. They include: Annie Kreitzer, principal designer for the experiment and the campaign and also team lead for integrated modeling of these experiments; Jean-Michel de Nicola, chief engineer for nif laser systems; and Alex Zylstra, the head of the NIF. They describe their roles in the project and how it relates to the overall goal of creating a design that can reach the extreme conditions required for Fusion ignition on a NIF (National Ignition Facility).\n",
            "\n",
            "Summary of chunk 2: Section #2 of the transcript discusses the continued support of the Department of Energy and the National Security Agency for the Mission. It also talks about the knife laser, the largest laser in the world, and its delivery of energy. The transcript then moves on to discuss the efforts to achieve ignition and the role of targets in this process. It also mentions the importance of diagnostics in understanding the conditions of the fusion plasma.\n",
            "\n",
            "Summary of chunk 3: Section #3: Scientific measurements to diagnose key quantities of the reacting fusion plasma such as temperature, energy yield, and duration. Diagnostics have critical for understanding what's going on and have been instrumental in identifying, quantifying, and mitigating degradations or loss mechanisms. These observations have been key to progress and will be even more important in the future as we move towards Fusion pilot plants.\n",
            "\n",
            "Summary of chunk 4: In this section of the video, John Collier talks about how his team prepared for the potential of a really exciting shot. He says they had to discussion with the laser science team over timing discrepancies of 25 trillionths of a second and had a discussion with the target team over flaws that are the size of a bacterium to decide if they're acceptable or not. They then grow a cryogenic DTI Slayer which which has the same sorts of requirements.\n",
            "\n",
            "Summary of chunk 5: In order to determine the amount of energy released during a laser-driven fusion reaction, scientists use diagnostic techniques such as measuring the number of neutrons that escape the target. This is done by placing a high purity metal sample close to the reaction and irradiating it with neutrons, which become radioactive and decay. The rate of activation and decay can then be measured, giving an accurate measurement of the number of neutrons that passed through the foil and the amount of energy released.\n",
            "\n",
            "Summary of chunk 6: The transcript section discusses the technical aspects of the shot, including the type of targets used and the amount of energy converted to energy during the shot. The speakers also answer questions from the audience about the cost of the targets and the amount of fuel converted to energy during the shot.\n",
            "\n",
            "Summary of chunk 7: The scientists involved in the experiment had dreams about what the outcome would be. One of the scientists was able to sleep through the night and received a text from another scientist letting her know the outcome. The target fabrication team's work ended a week before the shot, and they were hopeful about the outcome. The target wasn't delivered until a week before the shot, and the diagnostic team had high hopes.\n",
            "\n",
            "Summary of chunk 8: Section #8: The speaker discusses the advantages and disadvantages of magnetic confinement and inertial fusion, as well as the potential for machine learning to play a role in advancing.\n",
            "\n",
            "Summary of chunk 9: This section of the transcript is about a question from David Crandall about how the target for the August 8th 2021 experiment compared to the target for the August 12th 2021 experiment.\n",
            "\n",
            "Summary of chunk 10: In response to a question about why the yield increased, Dr. Benninghoven explains that the capsule quality was better in the August 2021 experiment than in the September experiment. He goes on to say that they were able to achieve 1.22 megajoules in the September experiment, which is attributed to the laser enhanced laser capability and the design change of the thicker Target.\n",
            "\n",
            "Summary of summaries: The following is a summary of the video on YouTube in 5-minute chunks: Chunk 1: The speakers introduce themselves as the principal designer for the experiment and the campaign and also team lead for integrated modeling of these experiments, Jean-Michel de Nicola, chief engineer for nif laser systems, and Alex Zylstra, the head of the NIF. They describe their roles in the project and how it relates to the overall goal of creating a design that can reach the extreme conditions required for Fusion ignition on a NIF. Chunk 2: Section #2 of the transcript discusses the continued support of the Department of Energy and the National Security Agency for the Mission. It also talks about the knife laser, the largest laser in the world, and its delivery of energy. The transcript then moves on to discuss the efforts to achieve ignition and the role of targets in this process. It also mentions the importance of diagnostics in understanding the conditions of the fusion plasma. Chunk 3: Section #3: Scientific measurements to diagnose key quantities of the reacting fusion plasma such as temperature, energy yield, and duration. Diagnostics have critical for understanding what's going on and have been instrumental in identifying, quantifying, and mitigating degradations or loss mechanisms. These observations have been key to progress and will be even more important in the future as we move towards Fusion pilot plants. Chunk 4: In this section of the video, John Collier talks about how his team prepared for the potential of a really exciting shot. He says they had to discussion with the laser science team over timing discrepancies of 25 trillionths of a second and had a discussion with the target team over flaws that are the size of a bacterium to decide if they're acceptable or not. They then grow a cryogenic DTI Slayer which which has the same sorts of requirements. Chunk 5: In order to determine the amount of energy released during a laser-driven fusion reaction, scientists use diagnostic techniques such as measuring the number of neutrons that escape the target. This is done by placing a high purity metal sample close to the reaction and irradiating it with neutrons, which become radioactive and decay. The rate of activation and decay can then be measured, giving an accurate measurement of the number of neutrons that passed through the foil and the amount of energy released. Chunk 6: The transcript section discusses the technical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQqu1OgCe89L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}