{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83TkFCvBK-1Z",
        "outputId": "417ee904-6924-4c08-878b-4fc8ba8f4a99"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install the following libraries: cohere to use the x-large model. \n",
        "!pip install cohere youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhJ8Xg6ELQCk",
        "outputId": "500d7b89-d67f-4765-fb5d-5011b53c1dd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cohere\n",
            "  Downloading cohere-3.3.2.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.5.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from cohere) (2.25.1)\n",
            "Collecting urllib3~=1.26\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->cohere) (4.0.0)\n",
            "Building wheels for collected packages: cohere\n",
            "  Building wheel for cohere (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cohere: filename=cohere-3.3.2-cp38-cp38-linux_x86_64.whl size=15691 sha256=58717a256202ab1308a76f159372f08f5540adba3823a359cd5c92f99ef8e41a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/e9/5f/3bb45881f18598535b297e45e50bab371e8f4b2078572668c2\n",
            "Successfully built cohere\n",
            "Installing collected packages: urllib3, youtube_transcript_api, cohere\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed cohere-3.3.2 urllib3-1.26.14 youtube_transcript_api-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GLi6usePVwQH"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/weblm/WebLM_interactive_src/cohereapikey.txt  /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6vGGA41hSge",
        "outputId": "c37ddcc5-5714-4b29-ff0c-540226885ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!mkdir /content/response_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# summarize a youtube video using cohere's "
      ],
      "metadata": {
        "id": "gomDjMZ1nB4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import sys\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from time import time,sleep\n",
        "import re\n",
        "\n",
        "diagnostics = 0\n",
        "include_mentions = 0\n",
        "\n",
        "\n",
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "def save_file(filepath, content):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "co= cohere.Client(open_file('/content/cohereapikey.txt'))\n",
        "\n",
        "def get_video_id_from_video_id_or_url(video_id_or_url):\n",
        "    # fetch the video ID from the URL. if it's more that 11 characters long, crop it to make it 11. \n",
        "    if len(video_id_or_url) > 11:\n",
        "        return video_id_or_url[-11:]\n",
        "    else:\n",
        "        return video_id_or_url\n",
        "\n",
        "def get_chunks_from_youtube(video_id):\n",
        "    # fetch video's transcript\n",
        "    # and chunk it into several 10min intervals\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "    chunks = []\n",
        "\n",
        "    start_timestamp = 0.0\n",
        "    current_timestamp_mins = 0.0\n",
        "\n",
        "    current_chunk = []\n",
        "\n",
        "    for entry in transcript:\n",
        "        current_timestamp_mins = entry['start'] / 60.0\n",
        "\n",
        "        # chunk at 10 minutes intervals\n",
        "        if current_timestamp_mins - start_timestamp > 10:\n",
        "            # add current chunk to a list of chunks\n",
        "            chunks.append(current_chunk)\n",
        "            # then reset the start timestamp\n",
        "            start_timestamp = current_timestamp_mins\n",
        "            # reset current chunk\n",
        "            current_chunk = []\n",
        "\n",
        "        # append the chunk's text\n",
        "        current_chunk.append(entry['text'])\n",
        "\n",
        "    # the last chunk of the video\n",
        "    if len(current_chunk) > 0:\n",
        "        chunks.append(current_chunk)\n",
        "\n",
        "    print(f\"Found {len(chunks)} chunks\")\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(index, chunk):\n",
        "    chunk_str = \"\\n\".join(chunk)\n",
        "    prompt = f\"\"\"The following is a section of the transcript of a youtube video. It is section #{index+1}:\n",
        "    {chunk_str}\n",
        "    Summarize this section of the transcript.\"\"\"\n",
        "\n",
        "    if diagnostics:\n",
        "        for line in prompt.split('\\n'):\n",
        "            print(f\"# {line}\")\n",
        "\n",
        "    \n",
        "    response = co.generate(\n",
        "                # model='xlarge'\n",
        "                model='command-beta',\n",
        "                prompt= prompt,\n",
        "                max_tokens=500,\n",
        "                temperature=1.8,\n",
        "                k=0,\n",
        "                p=0.65,\n",
        "                frequency_penalty=0.15,\n",
        "                presence_penalty=0.15,\n",
        "                stop_sequences=[],\n",
        "                return_likelihoods='NONE')\n",
        "    text_response = response.generations[0].text.strip()\n",
        "    text_response = re.sub('\\s+', ' ', text_response)\n",
        "    filename = '%s_logs.txt' % time()\n",
        "    with open('response_logs/%s' % filename, 'w') as outfile:\n",
        "        outfile.write('PROMPT:\\n\\n' + prompt + '\\n\\n==========\\n\\nRESPONSE:\\n\\n' + text_response)\n",
        "    with open('response.txt', 'w') as f:\n",
        "        f.write(text_response)\n",
        "    \n",
        "    if diagnostics:\n",
        "        print(f\"# Response: {text_response}\")\n",
        "    \n",
        "    return text_response\n",
        "\n",
        "def summarize_the_summaries(summaries):\n",
        "    max_retry = 5\n",
        "    retry = 0\n",
        "    summaries_str = \"\"\n",
        "    for index, summary in enumerate(summaries):\n",
        "        summaries_str += f\"Summary of chunk {index+1}:\\n{summary}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"The following are summaries of a youtube video in 10 minute chunks:\"\n",
        "    {summaries_str}\n",
        "    Summarize the summaries.\"\"\"\n",
        "\n",
        "    # prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
        "\n",
        "    if diagnostics:\n",
        "        for line in prompt.split('\\n'):\n",
        "            print(f\"# {line}\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            response = co.generate(\n",
        "                # model='xlarge'\n",
        "                model='command-beta',\n",
        "                prompt= prompt,\n",
        "                max_tokens=500,\n",
        "                temperature=1.8,\n",
        "                k=0,\n",
        "                p=0.65,\n",
        "                frequency_penalty=0.15,\n",
        "                presence_penalty=0.15,\n",
        "                stop_sequences=[],\n",
        "                return_likelihoods='NONE')\n",
        "            text_response = response.generations[0].text.strip()\n",
        "            text_response = re.sub('\\s+', ' ', text_response)\n",
        "            filename = '%s_log.txt' % time()\n",
        "            with open('response_logs/%s' % filename, 'w') as outfile:\n",
        "                outfile.write('PROMPT:\\n\\n' + prompt + '\\n\\n==========\\n\\nRESPONSE:\\n\\n' + text_response)\n",
        "            with open('response.txt', 'w') as f:\n",
        "                f.write(text_response)\n",
        "            return text_response\n",
        "        except Exception as oops:\n",
        "            retry += 1\n",
        "            if retry >= max_retry:\n",
        "                return \"error: %s\" % oops\n",
        "            print('Error communicating with Cohere:', oops)\n",
        "            sleep(1)\n",
        "\n",
        "    if diagnostics:\n",
        "        print(f\"# Response: {text_response}\")\n",
        "\n",
        "    return text_response\n",
        "\n",
        "def main():\n",
        "    # the video transcript\n",
        "    if len(sys.argv) < 2:\n",
        "        print(\"Usage: python3 sumvid.py <video id or url>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    video_id_or_url = sys.argv[1]\n",
        "\n",
        "    # if the video id or url is a url, extract the video id\n",
        "    video_id = get_video_id_from_video_id_or_url(video_id_or_url)\n",
        "\n",
        "    if len(sys.argv) > 2:\n",
        "        for arg in sys.argv[2:]:\n",
        "            if arg == \"--diagnostics\":\n",
        "                global diagnostics\n",
        "                diagnostics = True\n",
        "\n",
        "            if arg == \"--mentions\":\n",
        "                global include_mentions\n",
        "                include_mentions = True\n",
        "\n",
        "    chunks = get_chunks_from_youtube(video_id)\n",
        "\n",
        "    if len(chunks) == 0:\n",
        "        print(\"No chunks found\")\n",
        "    elif len(chunks) == 1:\n",
        "        summary = summarize_chunk(0, chunks[0])\n",
        "        print(f\"\\nSummary: {summary}\")\n",
        "\n",
        "    else:\n",
        "        # summarize each chunk\n",
        "        summaries = []\n",
        "        for index, chunk in enumerate(chunks):\n",
        "            summary = summarize_chunk(index, chunk)\n",
        "            summaries.append(summary)\n",
        "            print(f\"\\nSummary of chunk {index+1}: {summary}\")\n",
        "\n",
        "        # compile the summaries\n",
        "        summary_of_summaries = summarize_the_summaries(summaries)\n",
        "\n",
        "        print(f\"\\nSummary of summaries: {summary_of_summaries}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2glh9aornBqN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with mentions of people and places\n",
        "%cd /content\n",
        "!python3 /content/summarize_youtube.py https://www.youtube.com/watch?v=3m2Cpbpr1zM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkm2l1pEpo3e",
        "outputId": "d0e2cc1e-ba63-4d5b-e49b-abf68251be24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Found 1 chunks\n",
            "\n",
            "Summary: Section #1: David is explaining how to play a game where you silently signal to your partner if you trust a tradesman or not. He pretends that Bob is a tradesman and Alice is his wife. Bob comes to repair their broadband and David tells Alice to get the door. Alice introduces herself and David to Bob. David asks Bob how much it will cost to fix the broadband, and Bob says it will cost 2000 pounds. David is shocked and asks if he is telling the truth, and Alice says no.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/summarize_youtube.py https://www.youtube.com/watch?v=E_sMa3N44u4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw8V_5h7eV5z",
        "outputId": "890abb25-1af4-4831-e867-40b11562a626"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4 chunks\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/summarize_youtube.py\", line 212, in <module>\n",
            "    main()\n",
            "  File \"/content/summarize_youtube.py\", line 202, in main\n",
            "    summary = summarize_chunk(index, chunk)\n",
            "  File \"/content/summarize_youtube.py\", line 101, in summarize_chunk\n",
            "    text_response = response.generations[0].text.strip()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/response.py\", line 54, in __getattribute__\n",
            "    return attr.resolve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/response.py\", line 41, in resolve\n",
            "    self._result = self._getter(self._request.result())\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/client.py\", line 408, in __request\n",
            "    raise CohereError(\n",
            "cohere.error.CohereError: too many tokens: total number of tokens (prompt and prediction) cannot exceed 2048 - received 2578. Try using a shorter prompt, a smaller max_tokens value, or enabling prompt truncating. See https://docs.cohere.ai/reference/generate for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/summarize_youtube.py https://www.youtube.com/watch?v=JsLH0SeqAEc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM3HyxoqtPSA",
        "outputId": "368c7a70-0499-4dcc-e2f7-98c494d4da4b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 chunks\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/summarize_youtube.py\", line 212, in <module>\n",
            "    main()\n",
            "  File \"/content/summarize_youtube.py\", line 195, in main\n",
            "    summary = summarize_chunk(0, chunks[0])\n",
            "  File \"/content/summarize_youtube.py\", line 101, in summarize_chunk\n",
            "    text_response = response.generations[0].text.strip()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/response.py\", line 54, in __getattribute__\n",
            "    return attr.resolve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/response.py\", line 41, in resolve\n",
            "    self._result = self._getter(self._request.result())\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/client.py\", line 408, in __request\n",
            "    raise CohereError(\n",
            "cohere.error.CohereError: blocked input: please adjust your prompt and try again, as it may be a potential violation of our Usage Guidelines (https://docs.cohere.ai/usage-guidelines/).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/summarize_youtube.py https://youtu.be/_psRCXRyWq8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBIpwdMNqa5H",
        "outputId": "f9fbebfb-3e49-444d-fd40-e9d87d391f89"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 chunks\n",
            "\n",
            "Summary: Section #1 of the transcript is a description of the meniscus and how it can become injured. The meniscus is a type of cartilage that has two main functions: helps spread a person's weight evenly across the joint whilst also providing some stability. Injuries to the meniscus are often described as a cartilage tear. Arthroscopic punch and shaver are used to remove the torn fragment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/summarize_youtube.py https://www.youtube.com/watch?v=cTxBLn-DoEQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu9zID94br_x",
        "outputId": "7136f64a-fd50-418f-fae8-52e678b4172b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6 chunks\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/summarize_youtube.py\", line 212, in <module>\n",
            "    main()\n",
            "  File \"/content/summarize_youtube.py\", line 202, in main\n",
            "    summary = summarize_chunk(index, chunk)\n",
            "  File \"/content/summarize_youtube.py\", line 101, in summarize_chunk\n",
            "    text_response = response.generations[0].text.strip()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/response.py\", line 54, in __getattribute__\n",
            "    return attr.resolve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/response.py\", line 41, in resolve\n",
            "    self._result = self._getter(self._request.result())\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/cohere/client.py\", line 408, in __request\n",
            "    raise CohereError(\n",
            "cohere.error.CohereError: too many tokens: total number of tokens (prompt and prediction) cannot exceed 2048 - received 2260. Try using a shorter prompt, a smaller max_tokens value, or enabling prompt truncating. See https://docs.cohere.ai/reference/generate for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQqu1OgCe89L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}